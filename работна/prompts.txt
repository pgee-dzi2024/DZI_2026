Ще ти дам кратко, но подредено обяснение, фокусирано върху това, което реално ти трябва за проекта.

1. Какво е Live Streaming през уеб?
Live streaming = предаване на видео в реално време през интернет към един или повече клиенти (браузъри, мобилни приложения).

Общият процес:

Камерата подава видео (и евентуално аудио).
Сървър/приложение приема видеото, обработва го (компресира, прекодира, реже на части).
Клиентите се свързват към сървъра и получават кадрите/сегментите, които визуализират „на живо“.
В твоя случай:

камера → Python приложение (Django) → стрийм към браузъра (Vue).
2. Основни подходи за стрийм през уеб
2.1. MJPEG / HTTP Multipart Streaming
Най-простият вариант за уебкамера и Python.
Сървърът праща последователност от JPEG кадри през HTTP отговор с тип
Content-Type: multipart/x-mixed-replace; boundary=frame.
Браузърът показва това все едно е „движеща се“ снимка.
Плюсове:

Много лесно за имплементация с OpenCV + Django/Flask.
Работи в браузър без специални плейъри.
Минуси:

Не е много ефективно (JPEG за всеки кадър).
Няма адаптивно качество, няма стандартни контролери като при YouTube стил HLS.
За дипломния ти проект това е напълно достатъчно.

2.2. HTTP Streaming (HLS / MPEG-DASH) – по-теоретичната част
Това е по-съвременният подход, използван от платформи като YouTube, Twitch и др.

HLS (HTTP Live Streaming) – стандарт на Apple:

Видеото се разрязва на малки сегменти (например по 2–6 секунди).
Генерира се плейлист (M3U8 файл), който описва списъка с тези сегменти.
Браузърът/плейърът тегли последователно сегментите през обикновен HTTP/HTTPS.
Примерно:

stream.m3u8 – плейлист
segment1.ts, segment2.ts, segment3.ts, …
Особености:

Работи върху HTTP → лесно за CDN, кеширане, firewall-и.
Поддържа адаптивен битрейт (различни качества на видеото).
Не е съвсем „истински“ реално време (има закъснение 5–30 секунди).
В твоята теоретична част по „HTTP Streaming“ може да разгледаш:

Какво е HLS.
Как се дели видеото на сегменти.
Как работи M3U8 плейлист.
Разликата с прогресивно сваляне на видео (progressive download).
2.3. WebRTC (за пълно real-time)
Реално време с много ниска латентност (под секунда).
Използва UDP, специални протоколи (STUN/TURN, SRTP…).
По-сложно за имплементация – обикновено надхвърля нивото за училищен дипломен проект.
Вероятно можеш само да го споменеш в теоретичната част, без да го реализираш.

3. Как това се вързва с Python/Django/Vue
3.1. Python: достъп до камерата
Най-често:

OpenCV (cv2.VideoCapture(0)) за четене на кадри от камера.
На всеки кадър:
Показваш го на клиента като JPEG (за MJPEG streaming),
Плюс: използваш го за детекция на движение (разликата между два кадъра).
3.2. Django: HTTP endpoint за видео
Имаш view, който:

Връща StreamingHttpResponse с content_type="multipart/x-mixed-replace; boundary=frame".
Вътре в генератор функция:
Чете кадри от камерата,
Ги кодира в JPEG,
Ги yield-ва един по един като части от отговора.
Фронтендът (Vue) може да:

Вложи този URL в <img> или <video> таг,
Или да го зареди в компонент.
4. Детекция на движение (двукадрова разлика)
Идея:

Взимаш текущ кадър и предишен кадър.
Преобразуваш ги в сиво (cv2.cvtColor).
Изчисляваш разликата: cv2.absdiff(frame1, frame2).
Праг (threshold) → бинарно изображение.
Ако площта/брой бели пиксели е над определен праг → има движение.
Това може да работи паралелно със стрийма: всеки кадър, който така или иначе изпращаш към клиента, се анализира.

5. Какво да включиш в теоретичната част за „HTTP Streaming“
Можеш да структуриаш документацията така:

Въведение в Live Streaming
Какво е стрийминг, видове (VOD vs live).
HTTP Streaming
Какво е и защо се използва HTTP.
HLS като пример: сегменти, плейлист.
Алтернативи
RTMP (по-стар протокол за стрийм към сървъри като nginx-rtmp).
WebRTC за ниска латентност.
По-прости подходи за уебкамера
MJPEG стрийминг през HTTP (как работи multipart/x-mixed-replace).
Заключение
Защо в твоя проект избираш конкретен подход (например MJPEG или прост HTTP стрийм),
Компромис между сложност и функционалност.